"""Snakemake pipeline for Dapars2.
For help see: https://snakemake.readthedocs.io/en/stable/index.html.
"""

import pandas as pd
import os

configfile:"config/config.DaPars2.yaml"

samples = pd.read_csv(config["samples"]).set_index("sample", drop=False)


#-------------------------------------------------------------------------------
localrules: finish




rule finish:
    """Rule that specifies the final output.
    """
    input:
        samples = expand(
            os.path.join(config["out_dir"], "apa_{sample}"),
            sample=samples.index.values)
        # OUT1 = os.path.join(config["out_dir"],  "DaPars2_result_chr")
        # os.path.join(config["out_dir"], "01_DaPars2.BED")


#-------------------------------------------------------------------------------
# Preprocessing: obtain suitable input formats
rule addChrToGtf:
    """This step adds 'chr' prefix to gtf file.
    """
    input:
        gtf=config['gtf']
    output:
        out=os.path.join(config["out_dir"], "annotation_Chr.gtf")
    log:
        os.path.join(config["local_log"], "addChrToGtf.log")
    shell:
        """(awk '{{if($1 !~ /^#/){{print "chr"$0}}else{{print $0}}}}' {input.gtf} > {output.out}) &> {log}"""


rule addChrToGff3:
    """This step adds 'chr' prefix to gtf file.
    """
    input:
        gff3=config["gff3"]
    output:
        out=os.path.join(config["out_dir"], "annotation_Chr.gff3")
    log:
        os.path.join(config["local_log"], "addChrToGff3.log")
    shell:
        """(awk '{{if($1 !~ /^#/){{print "chr"$0}}else{{print $0}}}}' {input.gff3} > {output.out}) &> {log}"""


rule getBed12_1:
    """This step generates genePred from gff3. This is the first step for generate 12 column bed file.
    """
    input:
        gff3=os.path.join(config["out_dir"], "annotation_Chr.gff3")
    output:
        out=os.path.join(config["out_dir"], "annotation_Chr.genePred")
    conda:
        os.path.join(config["envs"], "DaPars2.yaml")
    log:
        os.path.join(config["local_log"], "getBed12_1.log")
    shell:
        """(gff3ToGenePred {input.gff3} {output.out}) &> {log}"""


rule getBed12_2:
    """This step generates 12 column bed file from genePed. This is the second step for generate 12 column bed file
    """
    input:
        genePred=os.path.join(config["out_dir"], "annotation_Chr.genePred")
    output:
        out=os.path.join(config["out_dir"], "annotation.bed")
    conda:
        os.path.join(config["envs"], "DaPars2.yaml")
    log:
        os.path.join(config["local_log"], "getBed12_2.log")
    shell:
        """(genePredToBed {input.genePred} {output.out}) &> {log}"""


rule extractGeneIdAndName:
    """This step extracts gene ID and gene symbol from gtf.
    """
    input:
        gtf=config["gtf"]
    output:
        out=os.path.join(config["out_dir"], "transcriptIdSymbol.txt")
    log:
        os.path.join(config["local_log"], "extractGeneIdAndName.log")
    shell:
        """(python workflow/scripts/extractIdSymbol.py <{input.gtf} > {output.out}) &> {log}"""



rule addChrToBam:
    """This is the second step of adding 'chr' prefix to bam files of samples. This process adds 'chr' prefix to bam body.
    """
    input:
        bam=lambda wildcards:
            pd.Series(samples.loc[wildcards.sample, "bam"]).values
    output:
        out=os.path.join(config["out_dir"], "{sample}.bam")
    conda:
        os.path.join(config["envs"], "DaPars2.yaml")
    log:
        os.path.join(config["local_log"], "{sample}addChrToBam.log")
    shell:
        """(samtools view -h {input.bam} | \
            sed -e '/^@SQ/s/SN\:/SN\:chr/' -e '/^[^@]/s/\t/\tchr/2' | \
            samtools view -bS - > {output.out}) &> {log}"""


rule sortBam:
    """This step sorts bam files with 'chr'.
    """
    input:
        bam=os.path.join(config["out_dir"], "{sample}.bam")
    output:
        out=os.path.join(config["out_dir"], "{sample}.sorted.bam")
    conda:
        os.path.join(config["envs"], "DaPars2.yaml")
    log:
        os.path.join(config["local_log"], "{sample}sortBam.log")
    threads:
        4
    shell:
        """(samtools sort -@ {threads} -o {output.out} {input.bam}) &> {log}"""


rule indexBam:
    """This step indexes sorted bam files.
    """
    input:
        bam=os.path.join(config["out_dir"], "{sample}.sorted.bam")
    output:
        out=os.path.join(config["out_dir"], "{sample}.sorted.bam.bai")
    conda:
        os.path.join(config["envs"], "DaPars2.yaml")
    log:
        os.path.join(config["local_log"], "{sample}indexBam.log")
    threads:
        4
    shell:
        """(samtools index -b -@ {threads} {input.bam}) &> {log}"""


rule generateBedgraph:
    """This step generates bedgraph files from sample bams. The bedgraph files will then processed by DaPars2.
    """
    input:
        bam=os.path.join(config["out_dir"], "{sample}.sorted.bam"),
        bai=os.path.join(config["out_dir"], "{sample}.sorted.bam.bai")
    output:
        out=os.path.join(config["out_dir"], "{sample}.bedgraph")
    conda:
        os.path.join(config["envs"], "DaPars2.yaml")
    log:
        os.path.join(config["local_log"], "{sample}generateBedgraph.log")
    shell:
        """(genomeCoverageBed -bg -ibam {input.bam} >{output.out}) &> {log}"""

    # conda:
    #     os.path.join(config["envs"], "DaPars2.yaml")
rule generatePathReadcounts:
    """This step counts the aligned read of each sample and write the abspaths and the numbers to a txt. The output will be assigned to DaPars2_config_file.txt and used for sequencing depth normalization.
    """
    input:
        bam=os.path.join(config["out_dir"], "{sample}.sorted.bam"),
        bai=os.path.join(config["out_dir"], "{sample}.sorted.bam.bai")
    output:
        out=os.path.join(config["out_dir"], "{sample}_pathReadcounts.tsv")
    params:
        basename= os.path.basename(os.path.join(config["out_dir"], "{sample}.sorted.bam"))
    log:
        os.path.join(config["local_log"],"{sample}generatePathReadcounts.log")
    shell:
        """(echo "{params.basename}"'\t'$(samtools view -c -F 260 {input.bam}) >{output.out}) &> {log}"""

# rule generatePathReadcounts_aggregate:
#     """This step aggregates the output of generatePathReadcounts.
#     """
#     input:
#         bams = expand(
#             os.path.join(config["out_dir"], "{sample}_pathReadcounts.tsv"),
#             sample=samples.index.values)
#     output:
#         out=os.path.join(config["out_dir"], "pathReadcounts.tsv")
#     log:
#         os.path.join(config["local_log"],"generatePathReadcounts_aggregate.log")
#     shell:
#         """(cat {input.bams} > {output.out}) &> {log}"""

#-------------------------------------------------------------------------------
# Method-specific rules
rule getRegionAnnotation:
    """This step generate 3UTR region annotation.
    """
    input:
        bed = os.path.join(config["out_dir"], "annotation.bed"),
        symbol = os.path.join(config["out_dir"], "transcriptIdSymbol.txt")
    output:
        out = os.path.join(config["out_dir"], "extracted_3UTR.bed")
    conda:
        os.path.join(config["envs"], "DaPars2.yaml")
    log:
        os.path.join(config["local_log"], "getRegionAnnotation.log")
    shell:
        """(python2 workflow/scripts/DaPars_Extract_Anno.py \
        -b {input.bed} \
        -s {input.symbol} \
        -o {output.out}) &> {log}"""

    #    conda:
    #     os.path.join(config["envs"], "DaPars2.yaml")

rule makeDapars2Config:
    """This step makes configure file for DaPars2.
    """
    input:
        bed = os.path.join(config["out_dir"], "annotation.bed"),
        seqDepth = os.path.join(config["out_dir"], "{sample}_pathReadcounts.tsv"),
        bedgraph = os.path.join(config["out_dir"], "{sample}.bedgraph")
    output:
        out=os.path.join(config["out_dir"], "{sample}_Dapars2_configure_file.txt")

    params:
        ct=config["coverageThreshold"],
        bedgraph = os.path.abspath(os.path.join(config["out_dir"], "{sample}.bedgraph")),
        seqDepth = os.path.abspath(os.path.join(config["out_dir"], "{sample}_pathReadcounts.tsv")),
        bed = os.path.abspath(os.path.join(config["out_dir"], "annotation.bed")),
        out = os.path.abspath(os.path.join(config["out_dir"], "{sample}")),
        outfile = "result"
    threads: 4
    log:
        os.path.join(config["local_log"], "{sample}_makeDapars2Config")
    run:
        ct=params.ct
        thr=threads
        seqd = params.seqDepth
        with open(output.out, "w") as f:
            f.write("# The following file is the result of generate_region_annotation\n")
            f.write(f"Annotated_3UTR={str(params.bed)}\n")
            f.write(f"#A comma-separated list of bedgraph files of all samples\n")
            f.write(f"Aligned_Wig_files={params.bedgraph}\n")
            f.write(f"Output_directory={params.out}\n")
            f.write(f"Output_result_file={params.outfile}\n")
            f.write(f"Coverage_threshold={ct}\n")
            f.write(f"Num_Threads = {thr}\n")
            f.write(f"sequencing_depth_file={seqd}\n")
# sample_list=[]
# for i in input.bedgraph:
#                 sample_list.append(os.path.basename(i))
#             sample_list=','.join(sample_list)
#             sample_list=sample_list.strip(",")

checkpoint mainDapars2:
    """This step runs DaPars2 on multiple samples and multiple chromosomes.
    """
    input:
        config=os.path.join(config["out_dir"], "{sample}_Dapars2_configure_file.txt")
    output:
        outdir = directory(os.path.join(config["out_dir"], "{sample}"))
    conda:
        os.path.join(config["envs"], "DaPars2.yaml")
    log:
        os.path.join(config["local_log"], "{sample}execute.mainDapars2.log")
    shell:
        """(mkdir {output.out}; \
        python2 workflow/scripts/DaPars2_Multi_Sample_Multi_Chr.py {input.config}) &> {log}"""

def gather_chromosomes(wildcards):
    checkpoint_output = checkpoints.mainDapars2.get(
        **wildcards).output.outdir
    ivals = glob_wildcards(os.path.join(
        checkpoint_output, "result_{chromosome}")).chromosome
    pathout = os.path.join(
        config["output_dir"],
        wildcards.sample)
    return expand(
        os.path.join(
            pathout,
            "result_{chromosome}",
            "result_result_temp.{chromosome}.txt"),
        chromosome=ivals)

rule concat_chromosomes :
    """This step runs DaPars2 on multiple samples and multiple chromosomes.
    """
    input:
        chrs = gather_chromosomes
    output:
        out = os.path.join(config["out_dir"], "apa_{sample}")
    log:
        os.path.join(config["local_log"], "{sample}concat_chromosomes.log")
    shell:
        """(cat {input.chrs} > {output.out}) &> {log}"""


# #-------------------------------------------------------------------------------
# # Postprocessing: obtain suitable output formats (for benchmarks)

# rule catAllResults:
#     """
#     This step combines all the output txt in each chromosome directory.
#     Note: expand() with wildcard sample gathers all samples.

#     """
#     input:
#         expand(os.path.join(config["out_dir"], "{sample}", "DaPars2_result_chr[1-22XY]", "DaPars2_result_temp.chr[1-22XY].txt"), sample = samples.index)
#     output:
#         os.path.join(config["out_dir"], "01_DaPars2.BED")
#     log:
#         os.path.join(config["local_log"], "catAllResults.log")
#     shell:
#         # WIP
#         """(cat {input} {output}) &> {log}) &> {log}"""




#-------------------------------------------------------------------------------
# How did it go?
#-------------------------------------------------------------------------------
onsuccess:
    print("Workflow finished, no error")

onerror:
    print("An error occurred, check log at %s." % {log})
