"""Snakemake pipeline for Dapars2.
For help see: https://snakemake.readthedocs.io/en/stable/index.html.
"""

import pandas as pd
import os
import sys

configfile:"config/config.DaPars2.yaml"

samples = pd.read_csv(config["samples"]).set_index("sample", drop=False)


#-------------------------------------------------------------------------------
localrules: finish


rule finish:
    """Rule that specifies the final output.
    """
    input:
        final = expand(
            os.path.join(config["out_dir"], "merge_{sample}"),
            sample=samples.index.values)
        # OUT1 = os.path.join(config["out_dir"],  "DaPars2_result_chr")
        # os.path.join(config["out_dir"], "01_DaPars2.BED")

# https://evodify.com/snakemake-checkpoint-tutorial/
#-------------------------------------------------------------------------------
# Preprocessing: obtain suitable input formats
rule addChrToGtf:
    """This step adds 'chr' prefix to gtf file.
    """
    input:
        gtf=config['gtf']
    output:
        out=os.path.join(config["out_dir"], "annotation_Chr.gtf")
    log:
        os.path.join(config["local_log"], "addChrToGtf.log")
    shell:
        """(awk '{{if($1 !~ /^#/){{print "chr"$0}}else{{print $0}}}}' {input.gtf} > {output.out}) &> {log}"""


rule addChrToGff3:
    """This step adds 'chr' prefix to gtf file.
    """
    input:
        gff3=config["gff3"]
    output:
        out=os.path.join(config["out_dir"], "annotation_Chr.gff3")
    log:
        os.path.join(config["local_log"], "addChrToGff3.log")
    shell:
        """(awk '{{if($1 !~ /^#/){{print "chr"$0}}else{{print $0}}}}' {input.gff3} > {output.out}) &> {log}"""


rule getBed12_1:
    """This step generates genePred from gff3. This is the first step for generate 12 column bed file.
    """
    input:
        gff3=os.path.join(config["out_dir"], "annotation_Chr.gff3")
    output:
        out=os.path.join(config["out_dir"], "annotation_Chr.genePred")
    conda:
        os.path.join(config["envs"], "DaPars2.yaml")
    container:
        "docker://apaeval/dapars2:1.0"
    log:
        os.path.join(config["local_log"], "getBed12_1.log")
    shell:
        """(gff3ToGenePred {input.gff3} {output.out}) &> {log}"""


rule getBed12_2:
    """This step generates 12 column bed file from genePed. This is the second step for generate 12 column bed file
    """
    input:
        genePred=os.path.join(config["out_dir"], "annotation_Chr.genePred")
    output:
        out=os.path.join(config["out_dir"], "annotation.bed")
    conda:
        os.path.join(config["envs"], "DaPars2.yaml")
    container:
        "docker://apaeval/dapars2:1.0"
    log:
        os.path.join(config["local_log"], "getBed12_2.log")
    shell:
        """(genePredToBed {input.genePred} {output.out}) &> {log}"""


rule extractGeneIdAndName:
    """This step extracts gene ID and gene symbol from gtf.
    """
    input:
        gtf=config["gtf"]
    output:
        out=os.path.join(config["out_dir"], "transcriptIdSymbol.txt")
    log:
        os.path.join(config["local_log"], "extractGeneIdAndName.log")
    shell:
        """(python workflow/scripts/extractIdSymbol.py <{input.gtf} > {output.out}) &> {log}"""


rule getRegionAnnotation:
    """This step generate 3UTR region annotation.
    """
    input:
        bed = os.path.join(config["out_dir"], "annotation.bed"),
        symbol = os.path.join(config["out_dir"], "transcriptIdSymbol.txt")
    output:
        out = os.path.join(config["out_dir"], "extracted_3UTR.bed")
    conda:
        os.path.join(config["envs"], "DaPars2.yaml")
    container:
        "docker://apaeval/dapars2:1.0"
    log:
        os.path.join(config["local_log"], "getRegionAnnotation.log")
    shell:
        """(python /DaPars2/src/DaPars_Extract_Anno.py \
        -b {input.bed} \
        -s {input.symbol} \
        -o {output.out}) &> {log}"""


rule addChrToBam:
    """This is the second step of adding 'chr' prefix to bam files of samples. This process adds 'chr' prefix to bam body.
    """
    input:
        bam=lambda wildcards:
            pd.Series(samples.loc[wildcards.sample, "bam"]).values
    output:
        out=os.path.join(config["out_dir"], "{sample}.bam")
    conda:
        os.path.join(config["envs"], "DaPars2.yaml")
    container:
        "docker://apaeval/dapars2:1.0"
    log:
        os.path.join(config["local_log"], "{sample}_addChrToBam.log")
    shell:
        """(samtools view -h {input.bam} | sed -e '/^@SQ/s/SN\:/SN\:chr/' -e '/^[^@]/s/\t/\tchr/2' | samtools view -bS - > {output.out}) &> {log}"""


rule sortBam:
    """This step sorts bam files with 'chr'.
    """
    input:
        bam=os.path.join(config["out_dir"], "{sample}.bam")
    output:
        out=os.path.join(config["out_dir"], "{sample}.sorted.bam")
    params:
        prefix = os.path.join(config["out_dir"], "{sample}_temp")
    conda:
        os.path.join(config["envs"], "DaPars2.yaml")
    container:
        "docker://apaeval/dapars2:1.0"
    log:
        os.path.join(config["local_log"], "{sample}_sortBam.log")
    threads: 4
    shell:
        """(samtools sort \
        -T {params.prefix} \
        -@ {threads} \
        -o {output.out} \
        {input.bam}) &> {log}"""


rule indexBam:
    """This step indexes sorted bam files.
    """
    input:
        bam=os.path.join(config["out_dir"], "{sample}.sorted.bam")
    output:
        out=os.path.join(config["out_dir"], "{sample}.sorted.bam.bai")
    conda:
        os.path.join(config["envs"], "DaPars2.yaml")
    container:
        "docker://apaeval/dapars2:1.0"
    log:
        os.path.join(config["local_log"], "{sample}_indexBam.log")
    shell:
        """(samtools index {input.bam} {output.out}) &> {log}"""


rule generateBedgraph:
    """This step generates bedgraph files from sample bams. The bedgraph files will then processed by DaPars2.
    """
    input:
        bam=os.path.join(config["out_dir"], "{sample}.sorted.bam"),
        bai=os.path.join(config["out_dir"], "{sample}.sorted.bam.bai")
    output:
        out=os.path.join(config["out_dir"], "{sample}.bedgraph")
    conda:
        os.path.join(config["envs"], "DaPars2.yaml")
    container:
        "docker://apaeval/dapars2:1.0"
    log:
        os.path.join(config["local_log"], "{sample}_generateBedgraph.log")
    shell:
        """(genomeCoverageBed -bg -ibam {input.bam} >{output.out}) &> {log}"""


rule generatePathReadcounts:
    """This step counts the aligned read of each sample and write the abspaths and the numbers to a txt. The output will be assigned to DaPars2_config_file.txt and used for sequencing depth normalization.
    """
    input:
        bam=os.path.join(config["out_dir"], "{sample}.sorted.bam"),
        bai=os.path.join(config["out_dir"], "{sample}.sorted.bam.bai")
    output:
        out=os.path.join(config["out_dir"], "{sample}_pathReadcounts.tsv")
    params:
        basename= os.path.basename(os.path.join(config["out_dir"], "{sample}.sorted.bam"))
    container:
        "docker://apaeval/dapars2:1.0"
    log:
        os.path.join(config["local_log"],"{sample}_generatePathReadcounts.log")
    shell:
        """(echo "{params.basename}"'\t'$(samtools view -c -F 260 {input.bam}) >{output.out}) &> {log}"""


rule makeDapars2Config:
    """This step makes configure file for DaPars2.
    """
    input:
        bed = os.path.join(config["out_dir"], "extracted_3UTR.bed"),
        seqDepth = os.path.join(config["out_dir"], "{sample}_pathReadcounts.tsv"),
        bedgraph = os.path.join(config["out_dir"], "{sample}.bedgraph")
    output:
        out=os.path.join(config["out_dir"], "{sample}_Dapars2_configure_file.txt")
    params:
        ct=config["coverageThreshold"],
        bedgraph = os.path.abspath(os.path.join(config["out_dir"], "{sample}.bedgraph")),
        seqDepth = os.path.abspath(os.path.join(config["out_dir"], "{sample}_pathReadcounts.tsv")),
        bed = os.path.abspath(os.path.join(config["out_dir"],  "extracted_3UTR.bed")),
        out = os.path.join(config["out_dir"], "intermediate_{sample}", "apa"),
        outfile = "apa"
    threads: 16
    log:
        os.path.join(config["local_log"], "{sample}_makeDapars2Config")
    run:
        ct=params.ct
        thr=threads
        seqd = params.seqDepth
        with open(output.out, "w") as f:
            f.write("# The following file is the result of generate_region_annotation\n")
            f.write(f"Annotated_3UTR={str(params.bed)}\n")
            f.write(f"#A comma-separated list of bedgraph files of all samples\n")
            f.write(f"Aligned_Wig_files={params.bedgraph}\n")
            f.write(f"Output_directory={params.out}\n")
            f.write(f"Output_result_file={params.outfile}\n")
            f.write(f"Coverage_threshold={ct}\n")
            f.write(f"Num_Threads = {thr}\n")
            f.write(f"sequencing_depth_file={seqd}\n")



def getchromosomes(filename):
    chrs = set()
    with open(filename, 'r') as infile:
        for line in infile:
            if line.startswith('#'):
                continue
            else:
                chrs.add('chr' + line.split('\t')[0])
    chr_names = list(chrs)
    return chr_names

chromosomes = getchromosomes(config['gtf'])


rule mainDapars2:
    """This step runs DaPars2 on multiple samples and multiple chromosomes.
    """
    input:
        config = os.path.join(config["out_dir"], "{sample}_Dapars2_configure_file.txt")

    output:
        os.path.join(config["out_dir"], "intermediate_{sample}", "apa_{chr}", "apa_result_temp.{chr}.txt")

    params:
        chromosome = "{chr}"

    wildcard_constraints:
        chr = "|".join(chromosomes)

    conda:
        os.path.join(config["envs"], "DaPars2.yaml")

    container:
        "docker://apaeval/dapars2:1.0"

    log:
        os.path.join(config["local_log"], "{sample}_{chr}_execute.mainDapars2.log")
    shell:
        """
        python /DaPars2/src/Dapars2_Multi_Sample.py \
        {input.config} \
        {params.chromosome} \
        &> {log}
        """


rule concat_chromosomes:
    """This step runs DaPars2 on multiple samples and multiple chromosomes.
    """
    input:
        names = lambda wildcards: expand(os.path.join(
                            config["out_dir"],
                            "intermediate_{sample}",
                            "apa_{chr}",
                            "apa_result_temp.{chr}.txt"),
                        sample=wildcards.sample,
                        chr=chromosomes)
    output:
        out = os.path.join(config["out_dir"], "merge_{sample}")

    log:
        os.path.join(config["local_log"], "{sample}_concat_chromosomes.log")
    shell:
        """(python workflow/scripts/results_to_bed.py \
        -i '{input.names}' \
        -c bed \
        -o {output.out}) &> {log}"""



#-------------------------------------------------------------------------------
# How did it go?
#-------------------------------------------------------------------------------
onsuccess:
    print("Workflow finished, no error")

onerror:
    print("An error occurred, check log at %s." % {log})
