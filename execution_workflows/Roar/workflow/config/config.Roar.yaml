# Configuration file for snakemake pipeline

# Path to sample table
samples: "workflow/config/samples.csv"

# Name of 'control' condition found in 'condition' column of sample table (becomes denominator in Roar's metrics)
control_condition_key: "control"

# path to main output directory storing output files for run
out_dir: "roar_results"

# Path to Roar-compliant GTF file containing polyA site and exon annoations
roar_gtf: "mm.gtf"

# Specify the annotation type to which GTF provided to 'roar_gtf' corresponds
# must be one of 'single' or 'multiple'
annotation_type: 'single'

# Are input data stranded? 'True'/'False' (no quotes)
is_stranded: False

threads: 4
participant: "Roar"
# Alias for 'Challenge code'
paramcode: "AA"

# Flags to run/output files for each benchmarking challenge
# All flags are 'True/False' to 'switch on/off' rules to produce challenge output. Valid parameter values are:
# 'True': Run/output challenge files
# 'False': Don't run/output challenge files
# Note: Always set to False if the the tool does not output files compatible with a challenge
# Note: Do not enclose True/False in quotation marks
# If combinations of flags are incompatible with one another (e.g. run_differential requires a different workflow to run_quantification), this should be noted here and in the README

# Whether to run steps to produce output files for identification challenge
# **Roar is currently incompatible with the identification challenge (see README for details)**
run_identification: False

# Whether to run steps to produce output files for quantification challenge
# **Roar is currently incompatible with quantification challenge (see README for details)**
run_quantification: False

# Whether to run steps to produce output files for differential challenge
run_differential: True

identification_output_suffix: "01.bed"
quantification_output_suffix: "02.bed"
differential_output_suffix: "03.tsv"


# Settings
envs: "envs"
scripts: "workflow/scripts"
local_log: "logs/local_log"
cluster_log: "logs/cluster_log"
