"""Snakemake pipeline for [METHOD].
For help see: https://snakemake.readthedocs.io/en/stable/index.html.
"""

import pandas as pd
import sys

samples = pd.read_csv(os.path.abspath(
    config["samples"])).set_index("sample", drop=False)

assert isinstance(config["run_identification"], bool), f"'run_identification' must be True/False boolean, {config['run_identification']} (type {type(config['run_identification'])}) was provided"
assert isinstance(config["run_quantification"], bool), f"'run_quantification' must be True/False boolean, {config['run_quantification']} (type {type(config['run_quantification'])}) was provided"
assert isinstance(config["run_differential"], bool), f"'run_differential' must be True/False boolean, {config['run_differential']} (type {type(config['run_differential'])}) was provided"


def flag_info_message(flag_name, challenge_name):

    if config[flag_name]:
        sys.stderr.write(f"config['{flag_name}'] set to True - {challenge_name} challenge output to be generated\n")

    elif not config[flag_name]:
        sys.stderr.write(f"config['{flag_name}'] set to False - {challenge_name} challenge output will not be generated. Is this desired run mode?\n")


# # Info messages
flag_info_message("run_identification", "identification")
flag_info_message("run_quantification", "quantification")
flag_info_message("run_differential", "differential")

# Example code to enforce flags to False
# Use ONLY if a tool is incompatible with a given challenge
# Delete these lines if not applicable to your workflow

# if config["run_identification"] is not False:
#     raise ValueError("'run_identification' must be set to False as tool is incompatible with the identification challenge/does not perform this task (see README for details).")
#
# if config["run_quantification"] is not False:
#     raise ValueError("'run_quantification' must be set to False as tool is incompatible with the quantification challenge/does not perform this task (see README for details).")
#
# if config["run_differential"] is not False:
#     raise ValueError("'run_differential' must be set to False as tool is incompatible with the differential challenge/does not perform this task (see README for details).")


#-------------------------------------------------------------------------------
localrules: finish

rule finish:
    """Rule that specifies the final output. Add all output files needed for the different challenges here. OUTCODE: 01 for identification challenge, 02 for quantification challenge, 03 for differential expression challenge. For more info refer to https://github.com/iRNA-COSI/APAeval/blob/main/execution_workflows/README.md
    """
    input:
        expand(os.path.join(config["out_dir"],
                     config["challenge"],
                     config["method"],
                     "_".join([config["challenge"],
                               config["method"],
                               "{sample}" + config["identification_output_suffix"]
                               ]
                              )
                            ),
               sample=list(samples.index) if config["run_identification"] else []
               ),
        expand(os.path.join(config["out_dir"],
                     config["challenge"],
                     config["method"],
                     "_".join([config["challenge"],
                               config["method"],
                               "{sample}" + config["quantification_output_suffix"]
                               ]
                              )
                            ),
               sample=list(samples.index) if config["run_quantification"] else []
               ),
        os.path.join(config["out_dir"],
                     config["challenge"],
                     config["method"],
                     "_".join([config["challenge"],
                               config["method"],
                               config["differential_output_file"]
                               ]
                              )
                     ) if config["run_differential"] else []




#-------------------------------------------------------------------------------
# Preprocessing: obtain suitable input formats

rule preprocess_step_1:
    """A rule that does some preprocessing.
    This example copies input to output and writes stdout and stderr to log.
    """
    input:
        bam = lambda wildcards:
                pd.Series(
                    samples.loc[wildcards.sample, "bam"]
                ).values
    output:
        os.path.join(config["out_dir"],
                     "bam_files",
                     "{sample}.bam")
    log:
        os.path.join(config["local_log"], "preprocess_step_1.{sample}.log")
    shell:
        "(cp {input.bam} {output}) &> {log}"


#-------------------------------------------------------------------------------
# Method-specific rules

rule execute_container:
    """Execution rule in a container (e.g. Dockerfile).
    """
    input:
        bam = os.path.join(config["out_dir"],
                           "bam_files",
                           "{sample}.bam")
    output:
        out=os.path.join(config["out_dir"], "{sample}", "execute.out")
    params:
        param1 = 0,
        param2 = "PARAM_STRING"
    threads: 4
    container: # OR URL/TO/CONTAINER
        os.path.join(config["envs"], "[METHOD].Dockerfile")
    log:
        os.path.join(config["local_log"], "execute.{sample}.log")
    shell:
        "(EXECUTE_COMMAND \
            -i {input.bam} \
            -o {output.out} \
            -p1 {params.param1} \
            -p2 {params.param2}) \
            &> {log}"


#-------------------------------------------------------------------------------
# Postprocessing: obtain suitable output formats (for benchmarks)


rule postprocess_identification:
    """
    A rule that produces output files for the identification challenge
    """
    input:
        os.path.join(config["out_dir"], "{sample}", "execute.out"),
        # os.path.join(config["out_dir"], config["challenge"], config["method"],
        # "_".join(config["challenge"], config["method"], "OUTCODE.ext"))
    output:
        out = os.path.join(config["out_dir"],
                           config["challenge"],
                           config["method"],
                           "_".join([config["challenge"],
                                     config["method"],
                                     "{sample}" + config["identification_output_suffix"]
                                     ]
                                    )
                           )
    params:
        param1 = 0,
        param2 = "PARAM_STRING"
    threads: 4
    container: # OR URL/TO/CONTAINER
        os.path.join(config["envs"], "[METHOD].Dockerfile")
    log:
        os.path.join(config["local_log"], "postprocess_identification.{sample}.log")
    shell:
        """
        (EXECUTE_COMMAND \
        -i {input} \
        -o {output.out} \
        -p1 {params.param1} \
        -p2 {params.param2}) \
        &> {log}
        """


rule postprocess_quantification:
    """
    A rule that produces output files for the quantification challenge
    """
    input:
        os.path.join(config["out_dir"], "{sample}", "execute.out"),
        # os.path.join(config["out_dir"], config["challenge"], config["method"],
        # "_".join(config["challenge"], config["method"], "OUTCODE.ext"))
    output:
        out = os.path.join(config["out_dir"], config["challenge"], config["method"],
        "_".join([config["challenge"],
                  config["method"],
                  "{sample}" + config["quantification_output_suffix"]
                  ]
                 ))
    params:
        param1 = 0,
        param2 = "PARAM_STRING"
    threads: 4
    container: # OR URL/TO/CONTAINER
        os.path.join(config["envs"], "[METHOD].Dockerfile")
    log:
        os.path.join(config["local_log"], "postprocess_quantification.{sample}.log")
    shell:
        """
        (EXECUTE_COMMAND \
        -i {input} \
        -o {output.out} \
        -p1 {params.param1} \
        -p2 {params.param2}) \
        &> {log}
        """

rule postprocess_differential:
    """
    A rule that produces output files for the differential challenge
    """
    input:
        expand(os.path.join(config["out_dir"], "{sample}", "execute.out"),
               sample=samples.index)
    output:
        out = os.path.join(config["out_dir"],
                           config["challenge"],
                           config["method"],
                           "_".join([config["challenge"],
                                     config["method"],
                                     config["differential_output_file"]
                                     ]
                                    )
                           )
    params:
        param1 = 0,
        param2 = "PARAM_STRING"
    threads: 4
    container: # OR URL/TO/CONTAINER
        os.path.join(config["envs"], "[METHOD].Dockerfile")
    log:
        os.path.join(config["local_log"], "postprocess_differential.log")
    shell:
        """
        (EXECUTE_COMMAND \
        -i {input} \
        -o {output.out} \
        -p1 {params.param1} \
        -p2 {params.param2}) \
        &> {log}
        """

#-------------------------------------------------------------------------------
# How did it go?
#-------------------------------------------------------------------------------
onsuccess:
    print("Workflow finished, no error")

onerror:
    print("An error occurred, check log at %s." % {log})
